---
opendistro:
  tariff: ultra

  alerts:
    check_record:
      enabled: true
      exclude_indices:
        - lmru-p0860-qcms-prod
        - lmru-p0145-usd-production
        - lmru-p0177-quota-stage
        - lmru-p0188-saa-stock-repository-prod
    check_status:
      enabled: true
      red:
        severity_level: 4
      yellow:
        severity_level: 5
    fields_limit:
      enabled: true
      severity_level: 4
    big_index:
      enabled: true
      severity_level: 4
      limit: 2Gi
    ro_index:
      enabled: true
      for: "1m"
      severity_level: 3

  clusterSettings:
    persistent:
      "cluster.routing.allocation.disk.threshold_enabled": true
      "cluster.routing.allocation.disk.watermark.low": 87%
      "cluster.routing.allocation.disk.watermark.high": 90%
      "cluster.routing.allocation.disk.watermark.flood_stage": 95%
      "cluster.routing.allocation.node_concurrent_incoming_recoveries": 10
      "cluster.routing.allocation.node_concurrent_outgoing_recoveries": 10
      "cluster.routing.allocation.cluster_concurrent_rebalance": 5
      "cluster.routing.allocation.node_concurrent_recoveries": 5
      "indices.recovery.max_bytes_per_sec": 100mb
    transient:
      "cluster.routing.allocation.disk.threshold_enabled": true
      "cluster.routing.allocation.disk.watermark.low": 87%
      "cluster.routing.allocation.disk.watermark.high": 90%
      "cluster.routing.allocation.disk.watermark.flood_stage": 95%
      "cluster.routing.allocation.node_concurrent_incoming_recoveries": 10
      "cluster.routing.allocation.node_concurrent_outgoing_recoveries": 10
      "cluster.routing.allocation.cluster_concurrent_rebalance": 5
      "cluster.routing.allocation.node_concurrent_recoveries": 5
      "indices.recovery.max_bytes_per_sec": 100mb

  project: observability-elk
  platform: yandex

  cluster: production

  node_pref: p

  clusterDomain: obs-logs-a.p.mesh

  userlist:
    services: ["admin", "filebeat", "logstash", "kibana", "read_only_filebeat", "apiuser"]

  common:
    nodegroup: opendistro-common

  init:
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "init-image"
      tag: "0.0.2"

  opendistro:
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "opensearch"
      tag: "2.16.0"
    # custom - самодельные сертификаты только для старых серверов
    # cluster - выписываются при помощи k8s
    certificates: "custom"
    disk_threshold_critical: 90
    disk_threshold_warning: 86
    bauth: '<path:services/data/opensearch-obs-logs#observability-elk.opendistro.bauth.prod>'
    external:
      enabled: true
      username: elastic
      password: '<path:services/data/opensearch-obs-logs#observability-elk.external.password.prod>'
    loadbalancer:
      type: Internal
      traffic_policy: Local
      listener_subnet_id: e9ba1bdl42op3o87vja4
      sourceRanges:
        - 10.80.0.0/16
        - 10.203.112.0/20
        - 10.203.96.0/20
        - 10.220.0.0/16
        - 10.111.0.0/16
        - 10.217.13.99/32
        - 10.12.85.118/32
        - 10.12.92.0/25
        - 10.203.11.28/32
        - 10.203.10.254/32
        - 10.203.3.144/28
        - 10.203.56.48/28
      nodePort: 32059
    nodegroup: opendistro
    host: elastic-logs-a.obs.lmru.tech
    port_http: "9200"
    port_transport: "9300"
    port_metrics: "9600"
    localstorage: false
    pv_storageclass: network-ssd-nonreplicated
    pv_size: 2046Gi
    replicas: "10"
    limits:
      memory: 28Gi
    requests:
      cpu: 1
      memory: 28Gi
    s3_backup:
      enabled: true
      repos:
        - repository: s3-backup-new
          client: default
          access_key: '<path:services/data/opensearch-obs-logs#observability-elk.s3_backup_new.access_key.prod>'
          secret_key: '<path:services/data/opensearch-obs-logs#observability-elk.s3_backup_new.secret_key.prod>'
          scheme: https
          endpoint: "https://storage.yandexcloud.net"
          region: ru-central1
          max_snapshot_bytes_per_sec: "100m" # 40MB/s
          max_restore_bytes_per_sec: "100m"
          bucket: flant-obs-logs-a-prod-opendistro-new
    internal:
      cookiePassword: '<path:services/data/opensearch-obs-logs#opendistro.internal.cookiepassword>'
    keystore:
      - secretName: opendistro-s3-backup-new
        items:
          - key: s3.access_key
            path: s3.client.default.access_key
          - key: s3.secret_key
            path: s3.client.default.secret_key
    wait_cluster_green: true

  exporter:
    enabled: true
    samplelimit: "150000"
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "os-exporter"
      tag: "0.0.2"
    resources:
      requests:
        cpu: 100m
        memory: 512Mi
      limits:
        memory: 512Mi

  snapshot_exporter:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "os-snapshot-exporter"
      tag: "0.0.1"

  oneday_exporter:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "os-oneday-exporter"
      tag: "0.0.2"

  apiuser:
    elasticsearch:
      password: '<path:services/data/opensearch-obs-logs#apiuser.elasticsearch.password.stage>'
      username: apiuser
      roles:
        - admin

  admin:
    elasticsearch:
      username: admin
      roles:
        - admin
      password: '<path:services/data/opensearch-obs-logs#observability-elk.admin.password.prod>'
    madison_key: e7f148a959d6af4172215664b470ea225b180f9c9dab54414faf413120c6691d
    restore_madison_key: 892da7f422f1669fdfb2c3f3491ce9598538c2ecc52d429c805319070f1bd7c7

  read_only_filebeat:
    elasticsearch:
      username: read_only_filebeat
      password: '<path:services/data/opensearch-obs-logs#observability-elk.read_only_filebeat.password.prod>'
      roles:
        - readall
        - kibanauser

  csi:
    enabled: true
    attacher:
      image:
        repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
        name: "csi-attacher"
        tag: "0.0.1"
    driver_registrar:
      image:
        repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
        name: "csi-node-driver-registrar"
        tag: "0.0.1"
    provisioner:
      image:
        repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
        name: "csi-provisioner"
        tag: "0.0.1"
    s3:
      image:
        repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
        name: "csi-s3"
        tag: "0.0.1"

  recoverer:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "opensearch"
      tag: "2.16.0"
    sc_data_name: csi-s3
    sc_system_name: network-ssd
    pv_data_size: 10Gi
    pv_system_size: 10Gi
    memory: 6Gi
    cpu: 1

  vector:
    enabled: false

  filebeat:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "filebeat"
      tag: "0.0.2"
    resources:
      limits:
        memory: 1Gi
      requests:
        cpu: 30m
        memory: 1Gi
    elasticsearch:
      username: filebeat
      password: '<path:services/data/opensearch-obs-logs#observability-elk.filebeat.password.prod>'
      roles:
        - filebeat

  logstash:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "logstash"
      tag: "0.0.1"
    external:
      enabled: true
    loadbalancer:
      type: Internal
      traffic_policy: Local
      listener_subnet_id: e9ba1bdl42op3o87vja4
    sourceRanges:
      - 10.80.0.0/16
      - 10.203.112.0/20
      - 10.203.96.0/20
      - 10.220.0.0/16
    nodePort: 32060
    port: 5045
    tcpPort: 9045
    tcpnodePort: 32061
    replicas: 7
    workers: 8
    batch:
      size: 2048
      delay: 30
    queuesize: 1900mb
    loglevel: info
    resources:
      limits:
        memory: 12Gi
      requests:
        cpu: 1
        memory: 12Gi
    pv:
      size: 2Gi
      storageclass: network-ssd
    elasticsearch:
      username: logstash
      password: '<path:services/data/opensearch-obs-logs#observability-elk.logstash.password.prod>'
      roles:
        - filebeat
        - logstash
    exporter:
      enabled: true
      image:
        repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
        name: "logstash-exporter"
        tag: "0.0.1"
      port: "9304"

  kibana:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "opensearch-dashboards"
      tag: "2.16.0"
    index_patterns:
      enabled: true
      regex: '^(d8|lmru-[\w]+|[a-zA-Z\-]+|[\w\-]+)-([\w\-]*)(\d{4}.\d{2}.\d{2}(-\d{2})*)$'
      include_patterns:
        - "lmru-*"
    resources:
      limits:
        memory: 8Gi
      requests:
        cpu: 500m
        memory: 8Gi
    maxpayloadbytes: 1572864
    # must be < resources.request.memory : if resources.request.memory=1024M than maxoldspacesize = 1000Mb
    maxoldspacesize: 7000
    multidomain:
      enabled: true
    host: kibana-logs-a.obs.lmru.tech
    external_host: dashboards.logs.lmru.tech
    connecturl: dex-logs-a.obs.lmru.tech
    auth: '<path:services/data/opensearch-obs-logs#observability-elk.kibana.auth.prod>'
    elasticsearch:
      username: kibanaserver
      password: '<path:services/data/opensearch-obs-logs#observability-elk.kibana.password.prod>'
      roles: [""]

  cerebro:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "cerebro"
      tag: "0.0.1"
    host: cerebro-osaas-a-logs-a.obs.lmru.tech
    secret: '<path:services/data/opensearch-obs-logs#observability-elk.cerebro.secret.prod>'
    auth: '<path:services/data/opensearch-obs-logs#observability-elk.cerebro.auth.prod>'

  xtractor:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "xtractor"
      tag: "0.2.22"
    is_s3: true
    host: xtractor.logs.lmru.tech
    port: "9400"
    timeout: "120"
    opendistro: "opendistro-recoverer"
    kibana: "dashboards.logs.lmru.tech"

  xkibana:
    enabled: false

  shell_operator:
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "shell-operator"
      tag: "0.0.1"

  pv_retain_operator:
    enabled: true

  curator:
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "os-curator"
      tag: "0.0.1"

  retention:
    enabled: true

  dereplicator:
    enabled: true
    schedule: "0 1 * * *"
    days_count: 2

  danglingChecker:
    enabled: true
    schedule: "0 10 * * *"

  madison:
    key: 280ea36804f79a6d10943c7af3042a9d7fd63f8dee5f2b94fa9d63b5dcb40bab
    project: lm-elk

  sharding:
    # regex for sharding script, if index name matches this regex, sharding will not be done
    # to exclude more than one name use "abc|edf"
    exclude_indices: "elastiflow|lmru-p0955-ip-nc-stage"

  node_updater:
    enabled: false
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "node-updater"
      tag: "0.0.1"

  internal_ro_users_list: ["obs-read-user"]
  internal_ro_users:
    obs-read-user:
      password: '<path:services/data/opensearch-obs-logs#internal_ro_users.obs-read-user.password.prod>'
      indices:
        - lmru-*

  osecurity_extend:
    permission: |-
      - "cluster_composite_ops"
      - "cluster_monitor"
      - "data_access"
      - "indices_monitor"
      - "cluster:admin/opendistro/ad/*"
      - "indices:admin/*/get"
      - "indices:data/write/index"
      - "cluster:admin/opendistro/alerting/*"
      - "indices:admin/resolve/index"
      - "cluster:admin/opendistro/reports/definition/*"
      - "cluster:admin/opendistro/reports/instance/*"
      - "cluster:admin/opendistro/reports/menu/*"
      - "cluster:admin/opensearch/notifications/configs/*"
      - "cluster:admin/opensearch/notifications/test_notification"
      - "cluster:admin/opensearch/ql/datasources/read"
      - "cluster:admin/opensearch/notifications/features"
    groups: |-
      - crowd-obs-elk-users

  sheet_reporter:
    enabled: true
    image:
      repo: "docker-flant.art.lmru.tech/lmru/devops/opensearch--"
      name: "sheet-reporter"
      tag: "0.2.0"
    job:
      schedule: "50 22 * * *"
    app:
      server:
        port: "17700"
    googleServiceAccount:
      privateKeyID: '<path:services/data/opensearch-obs-logs#gsa.privatekeyid>'
      privateKey: '<path:services/data/opensearch-obs-logs#gsa.privatekey>'

billing-resource:
  resourceName: opendistro
