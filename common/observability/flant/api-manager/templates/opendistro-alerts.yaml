{{- if $.Values.enabled }}

{{- $env_list := list }}
{{- range $k,$v:= $.Values.namespace }}
   {{- if ne $k "_default" }}
     {{- $env_list = append $env_list $k }}
   {{- end }}
{{- end }}

{{- range $env_list }}
  {{- $environ := . }}

{{- if (pluck $environ $.Values.alerts.enable | first | default $.Values.alerts.enable._default) }}
{{- $namespace := pluck $environ $.Values.namespace | first | default $.Values.namespace._default }}
---
apiVersion: deckhouse.io/v1
kind: CustomPrometheusRules
metadata:
  name: monitoring-{{ $namespace }}
spec:
  groups:
  - name: opendistro.rules
    rules:
    - alert: ElasticDown-{{ $namespace }}
      labels:
        severity_level: {{ pluck $environ $.Values.alerts.ElasticDown.severity_level | first | default $.Values.alerts.ElasticDown.severity_level._default | quote }}
      annotations:
        description: |-
          Последний запрос от экспортера в кластер ElasticSearch был неудачным. Необходимо проверить состояние всех подов кластера
        summary: Кластер ElasticSearch в неймспейсе {{`{{$labels.namespace}}`}} недоступен
        plk_markup_format: markdown
        plk_protocol_version: "1"
        plk_labels_as_annotations: pod,instance
      for: 5m
      expr: |
        elasticsearch_clusterinfo_up{cluster="elasticsearch-{{ $environ }}"} < 1
    - alert: ElasticClusterRed-{{ $namespace }}
      labels:
        severity_level: {{ pluck $environ $.Values.alerts.ElasticClusterRed.severity_level | first | default $.Values.alerts.ElasticClusterRed.severity_level._default | quote }}
      annotations:
        description: |-
          Статус Red означает, что как минимум один primary шард и все его реплики не аллоцированы ни на одной из нод кластера
          Примеры команд для проверки состояния кластера:
          - `curl -sk -XGET https://127.0.0.1:9200/_cluster/health?pretty`
          - `curl -sk -XGET https://127.0.0.1:9200/_cluster/allocation/explain?pretty`
          Для выполнения команд потребуется авторизация
        summary: Кластер ElasticSearch {{`{{ $labels.cluster }}`}} в неймспейсе {{`{{ $labels.namespace }}`}} в статусе Red
        plk_markup_format: markdown
        plk_protocol_version: "1"
        plk_labels_as_annotations: pod,instance
      for: 1m
      expr: |
        sum by (cluster, namespace) (elasticsearch_cluster_health_status{color="red", cluster="elasticsearch-{{ $environ }}"} == 1)
    - alert: ElasticClusterYellow-{{ $namespace }}
      labels:
        severity_level: {{ pluck $environ $.Values.alerts.ElasticClusterYellow.severity_level | first | default $.Values.alerts.ElasticClusterYellow.severity_level._default | quote }}
      annotations:
        description: |-
          Статус Yellow означает, что как минимум у одного индекса есть реплика шарда, которая не аллоцирована ни на одной из нод кластера
          Примеры команд для проверки состояния кластера:
          - `curl -sk -XGET https://127.0.0.1:9200/_cluster/health?pretty`
          - `curl -sk -XGET https://127.0.0.1:9200/_cluster/allocation/explain?pretty`
          Для выполнения команд потребуется авторизация
        summary: Кластер ElasticSearch {{`{{ $labels.cluster }}`}} в неймспейсе {{`{{ $labels.namespace }}`}} в статусе Yellow
        plk_markup_format: markdown
        plk_protocol_version: "1"
        plk_labels_as_annotations: pod,instance
      for: 5m
      expr: |
        sum by (cluster, namespace) (elasticsearch_cluster_health_status{color="yellow", cluster="elasticsearch-{{ $environ }}"} == 1)
    - alert: ElasticReadOnlyIndex-{{ $namespace }}
      labels:
        severity_level: {{ pluck $environ $.Values.alerts.ElasticReadOnlyIndex.severity_level | first | default $.Values.alerts.ElasticReadOnlyIndex.severity_level._default | quote }}
      annotations:
        description: |-
          Один из индексов перешел в состояние read-only. Это могло произойти из за того, что в ElasticSearch закончилось место
          Команда для отмены состояния read-only:
          - `curl -sk -IXPUT -H "Content-Type: application/json" https://127.0.0.1:9200/all/_settings -d '{"index": {"blocks": {"read_only_allow_delete": "false"}}}'`
          Для выполнения команды потребуется авторизация
        summary: В кластере ElasticSearch в неймспейсе {{`{{ $labels.namespace }}`}} есть индексы в статусе read-only
        plk_markup_format: markdown
        plk_protocol_version: "1"
        plk_labels_as_annotations: pod,instance
      for: 5m
      expr: |
        elasticsearch_indices_settings_stats_read_only_indices{cluster="elasticsearch-{{ $environ }}"} > 1
    - alert: ElasticUnassignedShards-{{ $namespace }}
      labels:
        severity_level: {{ pluck $environ $.Values.alerts.ElasticUnassignedShards.severity_level | first | default $.Values.alerts.ElasticUnassignedShards.severity_level._default | quote }}
      annotations:
        description: |-
          Количество unassigned шардов: {{`{{ $value }}`}}
          Полезные команды:
          - `curl -sk -XGET https://127.0.0.1:9200/_cluster/health?pretty`
          - `curl -sk -XGET https://127.0.0.1:9200/_cluster/allocation/explain?pretty`
          - `curl -sk -XPOST https://127.0.0.1:9200/_cluster/reroute?retry_failed`
          - `curl -sk -XGET "https://127.0.0.1:9200/_cat/recovery?v&pretty&active_only"`
          Для выполнения команд потребуется авторизация
        summary: В кластере ElasticSearch в неймспейсе {{`{{ $labels.namespace }}`}} есть unassigned шарды
        plk_markup_format: markdown
        plk_protocol_version: "1"
        plk_labels_as_annotations: pod,instance
      for: 5m
      expr: |
        sum by (cluster, namespace) (elasticsearch_cluster_health_unassigned_shards{cluster="elasticsearch-{{ $environ }}"} > 0)
    - alert: ElasticHeapUsageTooHigh-{{ $namespace }}
      labels:
        severity_level: {{ pluck $environ $.Values.alerts.ElasticHeapUsageTooHigh.severity_level | first | default $.Values.alerts.ElasticHeapUsageTooHigh.severity_level._default | quote }}
      annotations:
        description: |-
          Утилизация Java Heap на ноде {{`{{ $labels.name }}`}}: {{`{{ $value }}`}}
        summary: В кластере Elasticsearch {{`{{ $labels.cluster }}`}} у ноды {{`{{ $labels.name }}`}} в неймспейсе {{`{{ $labels.namespace }}`}} использовано Java Heap выше 80%
        plk_markup_format: markdown
        plk_protocol_version: "1"
        plk_labels_as_annotations: pod,instance
      for: 10m
      expr: |
        sum by(cluster, name, namespace) (round(elasticsearch_jvm_memory_used_bytes{area="heap", cluster="elasticsearch-{{ $environ }}"} / elasticsearch_jvm_memory_max_bytes{area="heap", cluster="elasticsearc`h-{{ $environ }}"} * 100)) > 80
    - alert: ElasticHeapUsageTooHigh-{{ $namespace }}
      labels:
        severity_level: {{ pluck $environ $.Values.alerts.ElasticHeapUsageTooHigh.severity_level | first | default $.Values.alerts.ElasticHeapUsageTooHigh.severity_level._default | quote }}
      annotations:
        description: |-
          Утилизация Java Heap на ноде {{`{{ $labels.name }}`}}: {{`{{ $value }}`}}
        summary: В кластере Elasticsearch {{`{{ $labels.cluster }}`}} у ноды {{`{{ $labels.name }}`}} в неймспейсе {{`{{ $labels.namespace }}`}} использовано Java Heap выше 90%
        plk_markup_format: markdown
        plk_protocol_version: "1"
        plk_labels_as_annotations: pod,instance
      for: 10m
      expr: |
        sum by(cluster, name, namespace) (round(elasticsearch_jvm_memory_used_bytes{area="heap", cluster="elasticsearch-{{ $environ }}"} / elasticsearch_jvm_memory_max_bytes{area="heap", cluster="elasticsearch-{{ $environ }}"} * 100)) > 90
    - alert: ElasticBackupIndiciesFailed-{{ $namespace }}
      labels:
        severity_level: {{ pluck $environ $.Values.alerts.ElasticBackupIndiciesFailed.severity_level | first | default $.Values.alerts.ElasticBackupIndiciesFailed.severity_level._default | quote }}
      annotations:
        description: |-
          Произошла ошибка в создание снапшота s3-backup для проверки: в кибане нужно проверить снапшот в devtools командой "GET _cat/snapshots/s3-backup",если в ответе будет failed, то проверить индекс и его состояние в кибане в index management > indices, посмотреть логи подов на наличие ошибок
        summary: Произошла ошибка в создание снапшота s3-backup
        plk_markup_format: markdown
        plk_protocol_version: "1"
        plk_labels_as_annotations: pod,instance
      for: 10m
      expr: |
        elasticsearch_snapshot_stats_snapshot_number_of_failures > 0
  - name: elk.pvc
    rules:
    - alert: ElkOrphanPvcDetected-{{ $namespace }}
      annotations:
        description: |
          The number of pvc is not equal to the number of replicas of sts Elasticsearch in namespace {{ $namespace }}. Please, check it.
        plk_markup_format: markdown
        plk_protocol_version: "1"
        summary: |
          The number of pvc is not equal to the number of replicas of sts Elasticsearch in namespace {{ $namespace }}. Please, check it.
      expr: count by (namespace) (kube_persistentvolumeclaim_info{namespace="{{ $namespace }}", persistentvolumeclaim=~".*elasticsearch.*", persistentvolumeclaim!~".*recoverer.*"}) != count by (namespace) (kube_pod_status_ready{namespace="{{ $namespace }}", pod=~".*elasticsearch.[0-9]*|.*elasticsearch-master.*", pod!~".*exporter.*", pod!~".*recoverer.*", condition="true"})
      for: 5m
      labels:
        severity_level: "5"
  - name: elk.disk
    rules:
    - alert: ElkStorageUtilizationIsLow-{{ $namespace }}
      annotations:
        plk_markup_format: markdown
        plk_protocol_version: "1"
        flant_incidents_flow: planned
        plk_pending_until_firing_for: "1m"
        plk_grouped_by__elk: ElkStorageUtilizationIsLowGroup
        plk_create_group_if_not_exists__elk: ElkStorageUtilizationIsLowGroup
        summary: |
          Elasticsearch cluster storage utilization is low.
        description: |
          The average storage utilization for the last 7 days is below 50%. Please review the number of Elasticsearch replicas.
      expr: avg_over_time(sum by (namespace) (kubelet_volume_stats_used_bytes{persistentvolumeclaim=~"data-elasticsearch-.*"})[7d:5m] offset 1w) / (sum by (namespace) (kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~"data-elasticsearch-.*"} offset 1w)) * 100 < 50 and on() day_of_week()==3 and on() hour()==7 and sum by (namespace)(elasticsearch_cluster_health_number_of_nodes{namespace="{{ $namespace }}"}) > 3
      for: 30m
      labels:
        severity_level: "6"
    - alert: ElkClusterHighDiskUtilisation-{{ $namespace }}
      annotations:
        description: |
          The average storage utilization for the last 1 hour is above 85%.
        plk_markup_format: markdown
        plk_protocol_version: "1"
        summary: |
          Elasticsearch cluster storage utilization is high.
      expr: avg_over_time(sum by (namespace) (kubelet_volume_stats_used_bytes{persistentvolumeclaim=~"data-elasticsearch-.*"})[1h:5m]) / (sum by (namespace) (kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~"data-elasticsearch-.*"})) * 100 > {{ $.Values.alerts.ElasticCheckDisk.limit }}
      for: 15m
      labels:
        severity_level: "{{ $.Values.alerts.ElasticCheckDisk.severity_level }}"
    - alert: ElkClusterDiskWriteLatencyTooHigh-{{ $namespace }}
      annotations:
        description: |
          The average time (in seconds) for write requests issued to the device to be served.
        plk_markup_format: markdown
        plk_protocol_version: "1"
        summary: |
          Elasticsearch cluster disk write latency is too high.
      expr: rate(node_disk_write_time_seconds_total{node=~".*opendistro-prod.*", device!="vda"}[2m]) / rate(node_disk_writes_completed_total{node=~".*opendistro-prod.*", device!="vda"}[2m])>{{ $.Values.alerts.ElkClusterDiskWriteLatencyTooHigh.limit }}
      for: 2m
      labels:
        severity_level: "{{ $.Values.alerts.ElkClusterDiskWriteLatencyTooHigh.severity_level }}"
{{- end }}

{{- end }}
{{- end }}
